{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = \"Test Notebook\"\n",
    "# author = \"Cindy Pino-Barrios\"\n",
    "# date = \"03-22-2023\"\n",
    "# description = \"testing nn.py, io.py, and preprocess.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nn.nn import NeuralNetwork\n",
    "from nn.preprocess import sample_seqs, one_hot_encode_seqs\n",
    "from nn.io import read_text_file, read_fasta_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the digit data to test nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()  # Load the digits dataset\n",
    "X, y = digits.data, digits.target  # X is the data, y is the target\n",
    "\n",
    "X = X/16  # Normalize the data\n",
    "\n",
    "# Split the data into training and testing sets (use 20% of the data for testing) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creat–µ an instance of the NeuralNetwork class with 64x16x64 autoencoder architecture with defined hyperparameters\n",
    "nn_arch = [{\"input_dim\": 64, \"output_dim\": 16, \"activation\": \"relu\"},\n",
    "           {\"input_dim\": 16, \"output_dim\": 64, \"activation\": \"sigmoid\"}]\n",
    "\n",
    "nn = NeuralNetwork(nn_arch, lr=0.01, seed=42, batch_size=8, epochs=1000,\n",
    "                   loss_function='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "train_loss, val_loss = nn.fit(X_train, X_train, X_val, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_forward():\n",
    "    # write a unit test to test the _single_forward method in the NeuralNetwork class\n",
    "    # this method takes in a W_curr: ArrayLike, b_curr: ArrayLike, A_prev: ArrayLike, and activation: str\n",
    "    # and returns the output of the forward pass for a single layer\n",
    "\n",
    "    W_curr = nn._param_dict['W1']\n",
    "    b_curr = nn._param_dict['b1']\n",
    "    A_prev = X_train[0]\n",
    "\n",
    "    A_curr, Z_curr = nn._single_forward(W_curr, b_curr, A_prev, 'relu')\n",
    "\n",
    "    assert A_curr.shape == (16,16)\n",
    "\n",
    "test_single_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward():\n",
    "\n",
    "    A_curr, Z_curr = nn.forward(X_train[0])\n",
    "    \n",
    "    assert A_curr.shape == (16,64)\n",
    "\n",
    "test_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_backprop():\n",
    "\n",
    "\n",
    "    W_curr = nn._param_dict['W1']\n",
    "    b_curr = nn._param_dict['b1']\n",
    "    A_prev = X_train[0]\n",
    "\n",
    "    \n",
    "\n",
    "    A_curr, Z_curr = nn._single_forward(W_curr, b_curr, A_prev, 'relu')\n",
    "    A_prev = A_curr\n",
    "\n",
    "\n",
    "    dZ_curr = nn._relu_backprop(A_curr, Z_curr)\n",
    "\n",
    "    dW_curr, db_curr, dA_prev = nn._single_backprop(W_curr, b_curr, Z_curr, A_prev, A_curr, 'relu')\n",
    "    \n",
    "\n",
    "    assert dW_curr.shape == (64,16)\n",
    "    assert db_curr.shape == (16,16)\n",
    "    assert dA_prev.shape == (16,1)\n",
    "\n",
    "test_single_backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    \n",
    "        y_pred = nn.predict(X_train)\n",
    "        \n",
    "    \n",
    "        assert y_pred.shape == (1437,64)\n",
    "\n",
    "test_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindybarrios/Desktop/BMI203_algorithms/final-nn-cb/nn/nn.py:437: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(1 / y.shape[1] * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)))\n"
     ]
    }
   ],
   "source": [
    "def test_binary_cross_error():\n",
    "\n",
    "    y_pred = nn.predict(X_train)\n",
    "    y_true = X_train\n",
    "\n",
    "    loss = nn._binary_cross_error(y_pred, y_true)\n",
    "\n",
    "    assert loss.shape == ()\n",
    "   \n",
    "\n",
    "test_binary_cross_error()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindybarrios/Desktop/BMI203_algorithms/final-nn-cb/nn/nn.py:453: RuntimeWarning: divide by zero encountered in divide\n",
      "  dA = - (np.divide(y, y_hat.T) - np.divide((1 - y), (1 - y_hat.T)))\n"
     ]
    }
   ],
   "source": [
    "def test_binary_cross_error_backprop():\n",
    "\n",
    "    y_pred = nn.predict(X_train)\n",
    "    y_true = X_train\n",
    "\n",
    "\n",
    "    dA = nn._binary_cross_error_backprop(y_pred.T, y_true)\n",
    "    \n",
    "\n",
    "    assert dA.shape == (64,1437)\n",
    "\n",
    "test_binary_cross_error_backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mean_squared_error():\n",
    "    \n",
    "        y_pred = nn.predict(X_train)\n",
    "        y_true = X_train\n",
    "\n",
    "    \n",
    "        loss = nn._mean_squared_error(y_pred, y_true)\n",
    "    \n",
    "        assert loss == 7.276754186796848\n",
    "        \n",
    "\n",
    "test_mean_squared_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mean_squared_error_backprop():\n",
    "\n",
    "    y_pred = nn.predict(X_train)\n",
    "    y_true = X_train\n",
    "\n",
    "\n",
    "    dA = nn._mean_squared_error_backprop(y_pred.T, y_true)\n",
    "    \n",
    "\n",
    "    assert dA.shape == (64,1437)\n",
    "\n",
    "test_mean_squared_error_backprop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing io.py and preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sample_seqs():\n",
    "    from nn.preprocess import sample_seqs\n",
    "\n",
    "    pos_seqs = read_text_file(\"data/test_pos_seqs.txt\")\n",
    "    neg_seqs = read_fasta_file('data/test_neg_seqs.fa')\n",
    "\n",
    "    assert len(pos_seqs) == 15\n",
    "    assert neg_seqs[0][0] == 'C'\n",
    "\n",
    "    # L:oading the data test_seqs.txt\n",
    "    file = \"/Users/cindybarrios/Desktop/BMI203_algorithms/final-nn-cb/data/test_data.txt\"\n",
    "    data = pd.read_csv(file, sep=',')\n",
    "\n",
    "    seqs = data['seqs'].values\n",
    "    labels = data['labels'].values\n",
    "\n",
    "    seqs = seqs.tolist()\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    X, y = sample_seqs(seqs, labels)\n",
    "\n",
    "    #print(X[0])\n",
    "    #print(y[0])\n",
    "\n",
    "    assert X[0] == 'ACATCCGTGCACCTCCG'\n",
    "    assert y[0] == 1\n",
    "\n",
    "    \n",
    "\n",
    "test_sample_seqs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_hot_encode_seqs():\n",
    "    from nn.preprocess import one_hot_encode_seqs\n",
    "    import numpy as np\n",
    "\n",
    "    # L:oading the data test_seqs.txt\n",
    "    file = \"/Users/cindybarrios/Desktop/BMI203_algorithms/final-nn-cb/data/test_data.txt\"\n",
    "    data = pd.read_csv(file, sep=',')\n",
    "\n",
    "    seqs = data['seqs'].values\n",
    "    labels = data['labels'].values\n",
    "\n",
    "    seqs = seqs.tolist()\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    X, y = sample_seqs(seqs, labels)\n",
    "\n",
    "    seqs = one_hot_encode_seqs(X) # One-hot encode the sequences\n",
    "    labels = np.array(y, dtype=int) # Convert the labels to a numpy array\n",
    "\n",
    "    #print(seqs[0][0])\n",
    "    #print(labels[0])\n",
    "\n",
    "    assert seqs[0][0] == 1\n",
    "    assert labels[0] == 1\n",
    "\n",
    "test_one_hot_encode_seqs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMI_203",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
